{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bhaav: A Multilingual Sentiment Aanalyzer for Indian Languages","metadata":{}},{"cell_type":"code","source":"import nltk\nimport pandas as pd\nfrom nltk.corpus import stopwords\nfrom textblob import Word\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import Counter\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom keras.models import Sequential\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\nfrom sklearn.model_selection import train_test_split ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-20T19:07:17.341344Z","iopub.execute_input":"2022-06-20T19:07:17.341854Z","iopub.status.idle":"2022-06-20T19:07:22.849687Z","shell.execute_reply.started":"2022-06-20T19:07:17.341820Z","shell.execute_reply":"2022-06-20T19:07:22.848333Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Loading the dataset\ndata = pd.read_csv('../input/imdb-dataset-sentiment-analysis-in-csv-format/Test.csv') ","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:07:22.855900Z","iopub.execute_input":"2022-06-20T19:07:22.856613Z","iopub.status.idle":"2022-06-20T19:07:23.040193Z","shell.execute_reply.started":"2022-06-20T19:07:22.856575Z","shell.execute_reply":"2022-06-20T19:07:23.039414Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:07:23.041378Z","iopub.execute_input":"2022-06-20T19:07:23.041726Z","iopub.status.idle":"2022-06-20T19:07:23.060051Z","shell.execute_reply.started":"2022-06-20T19:07:23.041692Z","shell.execute_reply":"2022-06-20T19:07:23.059199Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data.describe","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:07:23.061643Z","iopub.execute_input":"2022-06-20T19:07:23.062038Z","iopub.status.idle":"2022-06-20T19:07:23.072171Z","shell.execute_reply.started":"2022-06-20T19:07:23.062003Z","shell.execute_reply":"2022-06-20T19:07:23.071244Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Data Cleaning \ndef cleaning(df, stop_words):\n\n    df['text'] = df['text'].apply(lambda x: ' '.join(x.lower() for x in x.split()))\n\n    # Replacing the digits/numbers\n\n    df['text'] = df['text'].str.replace('d', '')\n\n    # Removing stop words\n\n    df['text'] = df['text'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop_words))\n\n    # Lemmatization\n\n    df['text'] = df['text'].apply(lambda x: ' '.join([Word(x).lemmatize() for x in x.split()]))\n\n    return df\n\nstop_words = stopwords.words('english')\n\ndata_v1 = cleaning(data, stop_words)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:07:23.073723Z","iopub.execute_input":"2022-06-20T19:07:23.074431Z","iopub.status.idle":"2022-06-20T19:07:31.038784Z","shell.execute_reply.started":"2022-06-20T19:07:23.074398Z","shell.execute_reply":"2022-06-20T19:07:31.037920Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_v1","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:07:31.039901Z","iopub.execute_input":"2022-06-20T19:07:31.040381Z","iopub.status.idle":"2022-06-20T19:07:31.052202Z","shell.execute_reply.started":"2022-06-20T19:07:31.040343Z","shell.execute_reply":"2022-06-20T19:07:31.051249Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Generating Embeddings\ntokenizer = Tokenizer(num_words=500, split=' ') \ntokenizer.fit_on_texts(data_v1['text'].values)\nX = tokenizer.texts_to_sequences(data['text'].values)\nX = pad_sequences(X)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T22:06:38.764849Z","iopub.execute_input":"2022-06-20T22:06:38.765397Z","iopub.status.idle":"2022-06-20T22:07:21.632546Z","shell.execute_reply.started":"2022-06-20T22:06:38.765365Z","shell.execute_reply":"2022-06-20T22:07:21.631649Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2022-06-20T22:07:26.568706Z","iopub.execute_input":"2022-06-20T22:07:26.569052Z","iopub.status.idle":"2022-06-20T22:07:26.574263Z","shell.execute_reply.started":"2022-06-20T22:07:26.569023Z","shell.execute_reply":"2022-06-20T22:07:26.573559Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"#Model Building\nmodel = Sequential()\nmodel.add(Embedding(500, 120, input_length = X.shape[1]))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(LSTM(704, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(352, activation='LeakyReLU'))\nmodel.add(Dense(2,activation='softmax'))\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:07:32.134108Z","iopub.execute_input":"2022-06-20T19:07:32.134506Z","iopub.status.idle":"2022-06-20T19:07:35.440069Z","shell.execute_reply.started":"2022-06-20T19:07:32.134447Z","shell.execute_reply":"2022-06-20T19:07:35.439310Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Splitting the data into training and testing\ny=pd.get_dummies(data_v1['label'])\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:07:35.442385Z","iopub.execute_input":"2022-06-20T19:07:35.442750Z","iopub.status.idle":"2022-06-20T19:07:35.462959Z","shell.execute_reply.started":"2022-06-20T19:07:35.442706Z","shell.execute_reply":"2022-06-20T19:07:35.462240Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Model Training\nmodel.fit(X_train, y_train, epochs = 20, batch_size=32, verbose =1)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T19:07:35.464260Z","iopub.execute_input":"2022-06-20T19:07:35.464613Z","iopub.status.idle":"2022-06-20T20:20:01.187012Z","shell.execute_reply.started":"2022-06-20T19:07:35.464580Z","shell.execute_reply":"2022-06-20T20:20:01.186200Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:20:01.190020Z","iopub.execute_input":"2022-06-20T20:20:01.190491Z","iopub.status.idle":"2022-06-20T20:20:07.759632Z","shell.execute_reply.started":"2022-06-20T20:20:01.190462Z","shell.execute_reply":"2022-06-20T20:20:07.758885Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Saving the model\nmodel.save(\"Bhaav\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T21:07:22.663844Z","iopub.execute_input":"2022-06-20T21:07:22.664215Z","iopub.status.idle":"2022-06-20T21:07:25.509504Z","shell.execute_reply.started":"2022-06-20T21:07:22.664178Z","shell.execute_reply":"2022-06-20T21:07:25.508684Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\nplot_model(model, show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T20:20:10.892475Z","iopub.execute_input":"2022-06-20T20:20:10.892836Z","iopub.status.idle":"2022-06-20T20:20:11.833952Z","shell.execute_reply.started":"2022-06-20T20:20:10.892801Z","shell.execute_reply":"2022-06-20T20:20:11.832978Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Saving the tokenizer\nimport pickle\nwith open('tokenizer.pickle', 'wb') as handle:\n    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T22:48:52.828823Z","iopub.execute_input":"2022-06-20T22:48:52.829181Z","iopub.status.idle":"2022-06-20T22:48:52.879309Z","shell.execute_reply.started":"2022-06-20T22:48:52.829138Z","shell.execute_reply":"2022-06-20T22:48:52.878545Z"},"trusted":true},"execution_count":160,"outputs":[]}]}